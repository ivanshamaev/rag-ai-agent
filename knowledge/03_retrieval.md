# Методы retrieval: Dense vs Sparse и гибридные подходы

**Retrieval** — процесс поиска релевантных документов или фрагментов, которые затем используются в генеративной модели (например, в RAG). Качество retrieval напрямую влияет на точность и надежность итогового ответа модели.

---

## Sparse retrieval (разреженный)

**Sparse**-подходы опираются на структуру текста и статистику слов.

### Как работает
- Представление текста как bag-of-words (мешок слов).
- Индексация термов через *inverted index*.
- Оценка релевантности через модели:
  - **BM25**
  - TF-IDF  
  - другие статистические методы

### Преимущества
- **Быстрый поиск**, хорошо оптимизирован в классических поисковых системах (ElasticSearch, Lucene).
- **Прозрачность и объяснимость**: понятно, почему документ выбран (совпадение важных термов).
- **Надёжность для термин-зависимых запросов**: если текст содержит конкретное слово — результат будет найден.

### Ограничения
- **Слабая семантика**: не понимает смысловых связей или перефразирований.
- **Чувствительность к словоформам, синонимам**:
  - «как сварить кофе» и «как приготовить кофе» могут считаться разными запросами.
- Ограниченная способность работать с длинными и разнородными коллекциями.

---

## Dense retrieval (плотный)

**Dense**-retrieval использует векторные представления (эмбеддинги), обученные на семантику.

### Как работает
- Запрос и документы преобразуются в векторы фиксированной размерности.
- Используется поиск ближайших соседей **ANN (Approximate Nearest Neighbor)**:
  - FAISS
  - HNSW
  - ScaNN
  - Milvus / Qdrant

### Преимущества
- **Сильная семантика**: понимает перефразирования, синонимы, скрытые смыслы.
- Устойчивость к разнородным формулировкам:
  - «рецепт кофе» ≈ «как приготовить напиток на основе эспрессо».
- Хорошо масштабируется в задачах semantic search и RAG.

### Ограничения
- Требует инфраструктуру для векторов: **векторная база** или эффективный ANN-индекс.
- **Дорогие операции обновления** индексов при динамических данных.
- Вычисление эмбеддингов может быть затратным (GPU/TPU).

---

## Гибридные подходы

На практике чаще всего работают **гибридные системы**, объединяющие sparse и dense retrieval.

### Стратегии
- **Two-stage retrieval**:
  1. Sparse (BM25) — быстрая фильтрация кандидатов.
  2. Dense — reranking по косинусному сходству.

- **Score fusion**:
  - объединение скорингов `w₁ * BM25 + w₂ * cosine_similarity`.

- **Parallel hybrid**:
  - два retriever'а работают параллельно, документы объединяются.

### Преимущества
- Лучшее соотношение **latency / качество**.
- Устойчивость к:
  - терминно-точным запросам (sparse)
  - семантически богатым запросам (dense)
- Особенно эффективны на больших коллекциях (миллионы+ документов).

---

## Архитектуры и практики

### ANN-индексы
- **FAISS** — индустриальный стандарт, GPU-ускорение, IVF/HNSW/PQ-индексы.
- **HNSW** — графовый индекс, быстрый recall, используется в:
  - *Milvus*
  - *Qdrant*
  - *Weaviate*
- **Annoy** — лёгкий, быстрый, но менее оптимальный по качеству.

### Метрики качества retrieval
- **Recall@k** — сколько релевантных документов нашли среди top-k.
- **Precision@k** — как много найденных документов действительно релевантны.
- **MRR**, **nDCG** — для более тонкого ранжирования.
- Латентность:
  - budget per request 20–100 ms для многих продакшн-RAG систем.

---

## Пояснение для новичка: базовые термины

- **Retriever** — компонент, который по запросу находит похожие документы.
- **Sparse (разреженный) поиск** — ищет совпадения по словам: быстрый и точный, но не понимает смысл.
- **Dense (плотный) поиск** — ищет по смыслу, используя эмбеддинги.
- **Hybrid (гибридный)** — объединяет оба подхода, чтобы получить лучшее качество.

### Простой пример
Запрос: **«как сделать кофе»**

- **Sparse** найдёт тексты, где буквально встречается слово «сделать» и «кофе».
- **Dense** найдёт статьи вроде «рецепт приготовления эспрессо», даже если нет слова «сделать».
- **Hybrid** — воспользуется преимуществами обоих и вернёт самый качественный набор документов.
