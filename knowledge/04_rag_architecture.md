# Архитектура RAG-систем

**Retrieval-Augmented Generation (RAG)** — архитектурный подход, в котором генеративная модель (LLM) дополняется механизмом retrieval.  
Цель RAG — повысить фактологичность и актуальность ответов, предоставляя модели внешние данные, которые она использует при генерации.

---

## Компоненты RAG

### 1. Хранилище документов
Источник данных, откуда система извлекает факты:
- файлы и корпоративные документы  
- базы данных  
- веб-страницы  
- API  
- структурированные и неструктурированные данные  

Это «сырьё» для построения индекса.

---

### 2. Indexer / Embedding Store
Хранилище, подготавливающее данные для поиска:
- **Sparse индекс** (BM25 / inverted index)  
- **Dense индекс** (векторная БД: Milvus, Qdrant, Weaviate, Chroma)  
- Метаданные + чанки  
- Поддержка обновлений, дедупликации, версионирования  

Indexer преобразует документы в фрагменты (чанки), создаёт эмбеддинги и сохраняет их.

---

### 3. Retriever
Компонент, выполняющий поиск по запросу пользователя:
- sparse (BM25)  
- dense (эмбеддинги + ANN)  
- hybrid поисковые стратегии  

Retriever возвращает top-k наиболее релевантных чанков.

---

### 4. Reranker (опционально)
Перераспределяет кандидаты по качеству, улучшая итоговый набор:
- Cross-encoder модели (например, специальные BERT-реранкеры)  
- LLM-based scoring  
- Weighted scoring (fusion методов)  

Reranker повышает точность retrieval, особенно в длинных коллекциях документов.

---

### 5. Generator
Генеративная модель, которая формирует финальный ответ:
- LLM (GPT, LLaMA, Mistral, Qwen и др.)  
- Использует retrieved контекст в prompt'e  
- Может ссылаться на источники, цитировать фрагменты  

Generator — «писатель», который опирается на материалы, полученные retriever’ом.

---

### 6. Контекстный менеджер
Управляет тем, как retrieved данные встраиваются в prompt:
- выбор оптимальных чанков  
- ограничение длины контекста  
- форматирование prompt'a  
- защита от переполнения контекстного окна  
- правила валидации retrieved данных (quality gates)  

Этот компонент отвечает за корректную и стабильную работу пайплайна.

---

## Варианты интеграции

### 1. Fusion-in-Decoder
- retrieved фрагменты подаются одновременно  
- LLM сама определяет, как их агрегировать  
- подходит для моделей с большим контекстным окном  
- улучшает устойчивость к шумным данным  

Это «мягкая» интеграция документов в процессе декодирования.

---

### 2. Retrieval-then-Generate (classic RAG)
Этапы:
1. retrieve  
2. concatenate в prompt  
3. generate  

Самый простой и распространённый вариант. Компактный, предсказуемый и хорошо работает в продакшене.

---

## Особенности проектирования RAG

### Управление контекстной длиной
- оптимальный размер чанка (150–500 токенов)  
- выбор количества retrieved фрагментов  
- фильтрация дубликатов  
- контроль за шумом и нерелевантными вставками  

Важно: слишком большой контекст ухудшает качество, а слишком маленький — теряет смысл.

---

### Инкрементальное обновление индексов
- обновление эмбеддингов при изменении документов  
- переиндексация новых/удалённых чанков  
- версионирование данных  
- поддержка свежести информации  

RAG-пайплайн должен уметь работать с постоянно меняющимися источниками.

---

### Трассировка источников (source attribution)
Важно указывать, **откуда** взяты факты:
- возврат ссылок на документы  
- маркировка чанков в ответе  
- возможность проверки корректности  
- предотвращение галлюцинаций  

Эта функция критична для систем поддержки принятия решений и корпоративных ассистентов.

---

## Пояснение для новичка: ключевые понятия

- **RAG** — не просим LLM помнить всё, а подставляем нужные документы во время запроса.  
- **Chunk (чанк)** — небольшой фрагмент текста, который индексируется отдельно, чтобы повысить точность поиска.  
- **Prompt engineering** — создание правильной структуры prompt'a, в который встроены retrieved фрагменты.

### Простая аналогия
Представьте:
- **Retriever** — библиотекарь, который по запросу достаёт подходящие книги и главы.  
- **Generator (LLM)** — писатель, который на основе этих глав формирует ответ.  
RAG объединяет их в одну систему.
