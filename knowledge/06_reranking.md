# Переранжирование (Reranking)

**Reranking** — это этап после первичного поиска, на котором система пересматривает и уточняет порядок найденных кандидатов (чанков или документов), используя более «умные» и дорогие модели. Это улучшает точность и качество итогового ответа в RAG-системах.

---

## Зачем нужен reranking

Retrieval (sparse или dense) оптимизирован под **скорость** и **recall**:  
он должен найти максимально широкий набор потенциально релевантных кандидатов.

Однако:
- Среди top-k результатов могут присутствовать нерелевантные фрагменты.  
- Порядок может быть далёк от идеального — важные фрагменты могут оказаться ниже.  
- Сложные запросы (многозначность, контекстные намёки, синонимы) требуют более глубокого анализа.

**Reranker повышает precision**, переставляя документы так, чтобы на первых местах были действительно лучшие по смыслу.

---

## Типы reranker-моделей

### 1) Cross-encoder (наиболее качественный)
- На вход подаётся пара: **[query] + [document]** (обычно concatenated через специальные токены).
- Модель оценивает релевантность, анализируя взаимодействия токенов между запросом и документом.
- Применяет полную self-attention между текстами.
- **Плюсы**: максимальное качество, глубокое понимание соответствия.  
- **Минусы**: высокая задержка, нельзя применить к большому числу кандидатов.

Обычно используется **для reranking топ-N** результатов, например 100 → 10.

Примеры моделей: *monoT5, MonoBERT, cross-encoder/ms-marco*.

---

### 2) Bi-encoder + MLP (быстрый, компромиссный)
- Query и документ кодируются **раздельно**, как в dense retrieval.
- Дополнительно используется небольшая нейросеть (MLP), которая принимает эмбеддинги и выдаёт score.
- Перекодировать текст можно заранее; дешёвый runtime.
- **Плюсы**: быстрый, масштабируемый.  
- **Минусы**: качество ниже, чем у cross-encoder (не видит взаимодействия между токенами внутри пары).

Применяется в системах с высоким трафиком или строгими latency-требованиями.

---

## Тренировка rerankers

Reranker обучается на выборках вида:
(query, positive, negative(s))


Где:  
- **positive** — релевантный документ;  
- **negative** — нерелевантный или «трудный» (hard negative) документ.

Используемые лоссы:
- **Contrastive loss** — учит модель различать positive vs negative.  
- **Margin-based loss** — настраивает разницу между positive и negative.  
- **Cross-entropy over softmax** — когда есть несколько документов с ранжированием.

Best practices:
- Добавлять **hard negatives** из dense/sparse retriever’ов.  
- Использовать датасеты MS MARCO, BEIR, Domain-specific разметку.

---

## Практики использования reranking

- Применять reranking **только к ограниченному числу кандидатов**:  
  например, первичный retriever выдаёт 200 кандидатов → reranker оценивает 20 → generator использует 5.
- Строить **каскад ранжирования**:
  1. Быстрый sparse или dense retriever (BM25 / HNSW)  
  2. Reranker (cross-encoder или bi-encoder+MLP)  
  3. Generator (LLM)

- Контролировать latency:
  - ограничивать длину документов  
  - использовать batching для cross-encoder  
  - применять quantization/LoRA для ускорения

- Добавлять reranker на этапе:
  - **retrieval** (лучшие кандидаты)  
  - **answer validation** (фильтрация нерелевантных фрагментов перед генерацией)

---

## Пояснение для новичка: зачем это всё

Reranker — это «второе мнение» после первичного поиска.

- Retriever быстро находит много кандидатов, но не всегда понимает тонкий смысл.  
- **Рерэнкинг** — это как эксперт, который читает уже отобранные фрагменты более внимательно и выбирает лучшие.  

### Простой пример

Вы ищете рецепт кофе:  
- Retriever находит 100 текстов со словом «кофе».  
- Reranker берёт топ-10, внимательно сравнивает каждый с запросом:  
  - где есть способ приготовления?  
  - какие ингредиенты описаны?  
  - это действительно рецепт, а не статья о кофейных зёрнах?  
- После этого reranker выдаёт 2–3 самых релевантных рецепта.

### Cross-encoder vs Bi-encoder для новичка
- **Cross-encoder** — как эксперт, который читает и вопрос, и документ одновременно, внимательно сравнивает слова.  
- **Bi-encoder** — как эксперт, который заранее прочитал все документы и теперь быстро сравнивает их характеристики с вашим вопросом.
